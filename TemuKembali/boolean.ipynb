{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df = pd.read_csv(r\"C:\\Users\\Lenovo\\TemuKembali\\data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>Judul</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The application of topic selection in teaching...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Teaching vocabulary through advertisements at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Good english teachers as perceived by secondar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Improving eighth grade students' writing throu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Learners preferences of multimedia resources i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No                                              Judul\n",
       "0   1  The application of topic selection in teaching...\n",
       "1   2  Teaching vocabulary through advertisements at ...\n",
       "2   3  Good english teachers as perceived by secondar...\n",
       "3   4  Improving eighth grade students' writing throu...\n",
       "4   5  Learners preferences of multimedia resources i..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'applic', 'of', 'topic', 'select', 'in', 'teach', 'speak', 'at', 'the', 'first', 'year', 'student', 'of', 'senior', 'high', 'school']\n",
      "['teach', 'vocabulari', 'through', 'advertis', 'at', 'the', 'first', 'grade', 'student', 'of', 'senior', 'high', 'school']\n",
      "['good', 'english', 'teacher', 'as', 'perceiv', 'by', 'secondari', 'school', 'student', 'in', 'indonesia']\n",
      "['improv', 'eighth', 'grade', 'student', 'write', 'through', 'the', 'use', 'of', 'cue', 'card', 'strategi']\n",
      "['learner', 'prefer', 'of', 'multimedia', 'resourc', 'in', 'an', 'extens', 'listen', 'cours']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_judul = 5\n",
    "dict_document_new = {} #Dictionary/penampung judul \n",
    "for i in range(n_judul):\n",
    "     dict_document_new['judul-' + str(i)] = df.iloc[i,1] #Penegisian dictionary \n",
    "dict_document_new \n",
    "\n",
    "number_pattern = r'[0-9]'\n",
    "punct_pattern = r'[^\\w\\s]'\n",
    "stop_words = set(stopwords.words('english')) \n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "for judul in dict_document_new:\n",
    "\n",
    "    dict_document_new[judul] = dict_document_new[judul] .casefold()\n",
    "\n",
    "    #numbers removal \n",
    "    dict_document_new[ judul] = re.sub(number_pattern,'',dict_document_new[judul]) \n",
    "\n",
    "    #punctuation removal \n",
    "    dict_document_new[judul] = re.sub(punct_pattern,'',dict_document_new[judul]) \n",
    "\n",
    "    #white space removal \n",
    "    dict_document_new[judul] = dict_document_new[ judul] .strip() \n",
    "\n",
    "    #tokenisasi \n",
    "    dict_document_new[judul] = nltk.word_tokenize(dict_document_new[judul])\n",
    "\n",
    "    #stemming\n",
    "    tokens = dict_document_new[judul]\n",
    "    tokens_new =[]\n",
    "    for token in tokens:\n",
    "        tokens_new.append(stemmer.stem(token))\n",
    "    dict_document_new[judul] = tokens_new \n",
    "\n",
    "    print(dict_document_new[judul])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 4,\n",
       " 'applic': 1,\n",
       " 'of': 5,\n",
       " 'topic': 1,\n",
       " 'select': 1,\n",
       " 'in': 3,\n",
       " 'teach': 2,\n",
       " 'speak': 1,\n",
       " 'at': 2,\n",
       " 'first': 2,\n",
       " 'year': 1,\n",
       " 'student': 4,\n",
       " 'senior': 2,\n",
       " 'high': 2,\n",
       " 'school': 3,\n",
       " 'vocabulari': 1,\n",
       " 'through': 2,\n",
       " 'advertis': 1,\n",
       " 'grade': 2,\n",
       " 'good': 1,\n",
       " 'english': 1,\n",
       " 'teacher': 1,\n",
       " 'as': 1,\n",
       " 'perceiv': 1,\n",
       " 'by': 1,\n",
       " 'secondari': 1,\n",
       " 'indonesia': 1,\n",
       " 'improv': 1,\n",
       " 'eighth': 1,\n",
       " 'write': 1,\n",
       " 'use': 1,\n",
       " 'cue': 1,\n",
       " 'card': 1,\n",
       " 'strategi': 1,\n",
       " 'learner': 1,\n",
       " 'prefer': 1,\n",
       " 'multimedia': 1,\n",
       " 'resourc': 1,\n",
       " 'an': 1,\n",
       " 'extens': 1,\n",
       " 'listen': 1,\n",
       " 'cours': 1}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_bank = {}  #statistik kata menanmpung kata2 yang dlm bhs inggris gak punya arti\n",
    "for judul in dict_document_new:\n",
    "    item = dict_document_new[judul]\n",
    "\n",
    "    for kata in item:\n",
    "        if kata not in token_bank:\n",
    "            token_bank[kata] = 1\n",
    "        else:\n",
    "            token_bank[kata] += 1\n",
    "token_bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jumlah kata unik: 42\n"
     ]
    }
   ],
   "source": [
    "print(\"jumlah kata unik: %d\" % (len(token_bank)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pola_angka = r'[0-9]'\n",
    "pola_simbol = r'[^/w/s]'\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "BOP = {\n",
    "    'not':3,\n",
    "    'and':2,\n",
    "    'or':1,\n",
    "    '(':0,\n",
    "    ')':0,\n",
    "}\n",
    "BO = list(BOP.keys())\n",
    "\n",
    "def preprocessing(teks):\n",
    "    #casefold\n",
    "    value = teks.casefold()\n",
    "\n",
    "    #hapus angka\n",
    "    value = re.sub(pola_angka,'',value)\n",
    "\n",
    "    #whitespace remove hapus space kri knan  query\n",
    "    value = value.strip()\n",
    "\n",
    "    #toketnisasi (memotong query jadi bbrp kata)\n",
    "    value = nltk.word_tokenize(value)\n",
    "\n",
    "    #steming (memotong kata jd bentuk dasar)\n",
    "    value_stem = []\n",
    "    for kata in value:\n",
    "        value_stem.append(stemmer.stem(kata))\n",
    "    value = value_stem\n",
    "\n",
    "    return value\n",
    "def infix2postfix(query):\n",
    "    #fungsi yang merubah infix jd postfix\n",
    "    infix = query\n",
    "    postfix = []\n",
    "    stack = []\n",
    "    scanned_operator = \"\"\n",
    "\n",
    "    if len(infix) > 0:\n",
    "        #lakukn proses\n",
    "        II = 0\n",
    "        while II < len(infix):\n",
    "            if infix[II] not in BO:\n",
    "                #ketika infix[II] not in BO jawabny \"iya\"\n",
    "                postfix.append(infix[II])\n",
    "                II += 1\n",
    "            else:\n",
    "                #ketika infix[II] not in BO jawabny \"tidak\"\n",
    "                scanned_operator = infix[II]\n",
    "                if len(stack) == 0:\n",
    "                    stack.append(scanned_operator)\n",
    "                    II += 1\n",
    "                elif scanned_operator == \"(\":\n",
    "                    stack.append(scanned_operator)\n",
    "                    II += 1\n",
    "                elif scanned_operator == \")\":\n",
    "                    postfix.append(stack.pop())\n",
    "                    while len(stack) != 0:\n",
    "                        if stack[-1] !=\"(\":\n",
    "                            postfix.append(stack.pop())\n",
    "                        else:\n",
    "                            stack.pop()\n",
    "                            while len(stack) != 0:\n",
    "                                if stack[-1] != \"(\":\n",
    "                                    postfix.append(stack.pop())\n",
    "                                else:\n",
    "                                    stack.pop()\n",
    "                            II += 1\n",
    "                        II += 1\n",
    "                elif BOP[stack[-1]] >= BOP[scanned_operator]:\n",
    "                    postfix.append(stack.pop())\n",
    "                    stack.append(scanned_operator)\n",
    "                    II += 1\n",
    "                else:\n",
    "                    stack.append(scanned_operator)\n",
    "                    II += 1\n",
    "            while len(stack) > 0:\n",
    "                postfix.append(stack.pop())\n",
    "    return postfix\n",
    "\n",
    "def booleanMapping(query,dokumen_judul):\n",
    "    mappedQuery = {}\n",
    "    BO = ['and','or','not']\n",
    "    for judul in dokumen_judul:\n",
    "        tempList = []\n",
    "        for item in query:\n",
    "            if item in BO:\n",
    "                tempList.append(item)\n",
    "            else:\n",
    "                if item in dokumen_judul[judul]:\n",
    "                    tempList.append(True)\n",
    "                else:\n",
    "                    tempList.append(False)\n",
    "        mappedQuery[judul] = tempList\n",
    "    return mappedQuery\n",
    "\n",
    "def evaluasiBoolean(mappedQuery):\n",
    "    evaluatedQuery = {}\n",
    "    BO = [\"no\",\"and\",\"or\"]\n",
    "    \n",
    "    for judul in mappedQuery:\n",
    "        new_query = mappedQuery[judul]\n",
    "        while len(new_query) > 1:\n",
    "            temp_query = []\n",
    "            for index, kata in enumerate(new_query):\n",
    "                if kata in BO:\n",
    "                    curr_pos = index\n",
    "                    if kata == \"not\":\n",
    "                        ml_pos = curr_pos -1\n",
    "                        #sektor kiri temp_query\n",
    "                        temp_query = temp_query + new_query[:ml_pos]\n",
    "                        #sktro tgh\n",
    "                        temp_query.append(not new_query[ml_pos])\n",
    "                        #sktro knan\n",
    "                        temp_query = temp_query + new_query[curr_pos+1:]\n",
    "\n",
    "                        #update nilai querr\n",
    "                        new_query = temp_query\n",
    "                        break\n",
    "                    elif kata == \"and\":\n",
    "                        ml_pos = curr_pos -2\n",
    "                        mr_pos = curr_pos -1\n",
    "                        #sektor kiri temp_query\n",
    "                        temp_query = temp_query + new_query[:ml_pos]\n",
    "                        #tegah\n",
    "                        temp_query.append(new_query[ml_pos] and new_query[mr_pos])\n",
    "                        #knan\n",
    "                        temp_query = temp_query + new_query[curr_pos+1:]\n",
    "\n",
    "                        #update nilai querr\n",
    "                        new_query = temp_query\n",
    "                        break\n",
    "                    elif kata == \"or\":\n",
    "                        ml_pos = curr_pos -2\n",
    "                        mr_pos = curr_pos -1\n",
    "                        #sektor kiri temp_query\n",
    "                        temp_query = temp_query + new_query[:ml_pos]\n",
    "                        #tegahh\n",
    "                        temp_query.append(new_query[ml_pos] or new_query[mr_pos])\n",
    "                        #knan\n",
    "                        temp_query = temp_query + new_query[curr_pos+1:]\n",
    "\n",
    "                        #update nilai querr\n",
    "                        new_query = temp_query\n",
    "                        break            \n",
    "        evaluatedQuery[judul] = new_query\n",
    "    return evaluatedQuery\n",
    "\n",
    "def tampilHasil(evaluatedQuery):\n",
    "    list_index = []\n",
    "    list_hasil = []\n",
    "\n",
    "    for judul in evaluatedQuery:\n",
    "        if evaluatedQuery[judul][0] == True:\n",
    "            judul_splited = judul.split(sep='-')\n",
    "            list_index.append( int( judul_splited[1] ) )\n",
    "    for index in list_index:\n",
    "        list_hasil.append(df.iloc[index,1])\n",
    "        \n",
    "    return list_hasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The application of topic selection in teaching speaking at the first year students of Senior High School',\n",
       " 'Teaching vocabulary through advertisements at the first grade students of Senior High School',\n",
       " 'Good english teachers as perceived by secondary school students in indonesia']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = input(\"masukan kata kunci pencarian: \")\n",
    "\n",
    "query = preprocessing(query)\n",
    "query = infix2postfix(query)\n",
    "query = booleanMapping(query,dict_document_new)\n",
    "query = evaluasiBoolean(query)\n",
    "hasil = tampilHasil(query)\n",
    "hasil"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
